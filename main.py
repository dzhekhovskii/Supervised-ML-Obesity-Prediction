# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hggFuiu-gXmxXZJDeklvlsKsEV8WLKm9

# **Machine Learning**
"""

# Import the libraries we need for ML

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

"""**Upload the datatset using Google Drive (Google Colab notebook)**"""

# Mount Google Drive to upload the dataset
from google.colab import drive
drive.mount('/content/drive')

#Check the dataset's path
!ls "/content/drive/My Drive/ObesityDataSet_preprocessed.csv"

#Upload the dataset from our Google Drive
file_path = "/content/drive/My Drive/ObesityDataSet_preprocessed.csv"
df = pd.read_csv(file_path, sep=',')

df

"""**Upload the dataset using one's PC (Visual Studio Code and others)**"""

# df = pd.read_csv(".../ObesityDataSet_preprocessed.csv", sep=";")

"""# **Feature Engineering**"""

# One-hot encoding

one_hot_cols = [
    'Gender',
    'family_history_with_overweight',
    'FAVC'
]

df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)

# Label encoding (mapping applied)

df['NCP'] = df['NCP'].map({
    3: 1,
    4: 1,
    1: 0,
    2: 0
})

df['CAEC'] = df['CAEC'].map({
    "no": 2,
    "Sometimes": 1,
    "Frequently": 1,
    "Always": 0
})

df['CALC'] = df['CALC'].map({
    "no": 2,
    "Sometimes": 1,
    "Frequently": 0,
    "Always": 0
})

df['MTRANS'] = df['MTRANS'].map({
    "Motorbike": 0,
    "Automobile": 0,
    "Public_Transportation": 1,
    "Walking": 2,
    "Bike": 2
})

# Transform target column

df['NObeyesdad'] = df['NObeyesdad'].map({
    "Insufficient_Weight": "Insufficient weight",
    "Normal_Weight": "Normal weight",
    "Overweight_Level_I": "Overweight",
    "Overweight_Level_II": "Overweight",
    "Obesity_Type_I": "Obesity",
    "Obesity_Type_II": "Obesity",
    "Obesity_Type_III": "Obesity"
})

"""# Modeling Workflow: Multi-Class Classification


"""

# LOAD DATA

X = df.drop(columns=['NObeyesdad'])
y = df['NObeyesdad']

# TRAIN/TEST SPLIT

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# STRATIFIED K-FOLD

cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# MODELS + GRID SEARCH SPACES

# Define models with extended hyperparameter grids
models = {
    "Logistic Regression": (
        LogisticRegression(max_iter=5000, class_weight="balanced", random_state=42),
        {
            "C": [0.01, 0.1, 1, 10],
            "solver": ["lbfgs"]  # just one solver, avoids NaNs
        }
    ),

    "Random Forest": (
        RandomForestClassifier(class_weight="balanced", random_state=42),
        {
            "n_estimators": [100, 200, 300],
            "max_depth": [None, 10, 20],
            "min_samples_split": [2, 5],
            "min_samples_leaf": [1, 2],
            "max_features": ["sqrt", "log2"],
            "bootstrap": [True]  # remove False to cut combinations
        }
    ),

    "kNN": (
        KNeighborsClassifier(),
        {
            "n_neighbors": [3, 5, 7],
            "weights": ["uniform", "distance"],
            "p": [1, 2]
        }
    ),

    "Naive Bayes": (
        GaussianNB(),
        {
            "var_smoothing": [1e-09, 1e-08, 1e-07]  # fewer options
        }
    )
}
# List to store results
results = []

# TRAIN + GRID SEARCH LOOP
for name, (model, params) in models.items():
    print(f"Training: {name}")

    # Create GridSearchCV for the current model with 5-fold CV
    grid = GridSearchCV(
        estimator=model,
        param_grid=params,
        cv=5,                # 5-fold cross-validation
        scoring="f1",        # better for imbalanced classes than accuracy
        n_jobs=-1,
        verbose=2
    )

    # Fit the grid search on training data
    grid.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = grid.predict(X_test)

    # Save results including best parameters
    results.append({
        'name': name,
        'model': grid,
        'y_pred': y_pred,
        'y_true': y_test,
        'best_params': grid.best_params_,
        'best_score': grid.best_score_
    })

# Print summary of best results
for res in results:
    print(f"{res['name']}: Best F1 = {res['best_score']}, Best Params = {res['best_params']}")

# SUMMARY: Accuracy + Weighted F1 + Confusion Matrix

print(" FINAL RESULTS SUMMARY ")

for model_info in results:
    name = model_info['name']
    y_pred = model_info['y_pred']
    y_true = model_info['y_true']

    acc = accuracy_score(y_true, y_pred)
    f1_w = f1_score(y_true, y_pred, average='weighted')
    cm = confusion_matrix(y_true, y_pred)

    print(f"\n{name}")
    print(f"Accuracy       : {acc:.4f}")
    print(f"Weighted F1    : {f1_w:.4f}")
    print("Confusion Matrix:")
    print(cm)

"""# Visualisations"""

# EXTRACT BEST RANDOM FOREST FROM RESULTS

rf = None
for r in results:
    if r['name'] == "Random Forest":
        rf = r['model']  # Best RandomForest from GridSearchCV
        break

if rf is None:
    raise ValueError("Random Forest model not found in results.")

print("Using best Random Forest:", rf.best_params_)

# PREDICTIONS

y_pred = rf.predict(X_test)
y_score = rf.predict_proba(X_test)

# 1. CONFUSION MATRIX HEATMAP

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(7,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu")
plt.title("Confusion Matrix - Best Random Forest")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# 2. ROC CURVE (MULTICLASS)

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import numpy as np

y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
n_classes = y_test_bin.shape[1]

plt.figure(figsize=(8,6))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"Class {i} (AUC={roc_auc:.2f})")

plt.plot([0,1], [0,1], "k--")
plt.title("ROC Curve - Best Random Forest")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# 3. PRECISION–RECALL CURVE

from sklearn.metrics import precision_recall_curve

plt.figure(figsize=(8,6))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])
    plt.plot(recall, precision, label=f"Class {i}")

plt.title("Precision–Recall Curve - Best Random Forest")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.legend()
plt.show()

# 4. FEATURE IMPORTANCE (SEABORN)

importances = rf.best_estimator_.feature_importances_
indices = np.argsort(importances)[::-1]
feature_names = X.columns

plt.figure(figsize=(8,6))
sns.barplot(x=importances[indices], y=feature_names[indices], palette="viridis")
plt.title("Feature Importance - Best Random Forest")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

# 5. SHAP VALUES (GLOBAL EXPLAINABILITY)

import shap

explainer = shap.TreeExplainer(rf.best_estimator_)
shap_values = explainer.shap_values(X_test)

# Summary plot (beeswarm)
shap.summary_plot(shap_values, X_test, plot_type="dot")

# Global importance bar plot
shap.summary_plot(shap_values, X_test, plot_type="bar")

"""# Download the model"""

import os
import joblib

save_dir = "saved_models"
os.makedirs(save_dir, exist_ok=True)

joblib.dump(rf, os.path.join(save_dir, "random_forest_best_model.pkl"))
print("Model saved in:", os.path.join(save_dir, "random_forest_best_model.pkl"))

from google.colab import files

files.download("saved_models/random_forest_best_model.pkl")